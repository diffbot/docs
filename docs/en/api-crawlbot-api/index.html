<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Crawlbot API · Docs Suite</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="The Crawlbot API allows you to programmatically manage &lt;a href=&quot;/dev/crawl&quot;&gt;Crawlbot&lt;/a&gt; crawls and retrieve output. Crawlbot API responses are in JSON format."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Crawlbot API · Docs Suite"/><meta property="og:type" content="website"/><meta property="og:url" content="https://diffbot.github.io/"/><meta property="og:description" content="The Crawlbot API allows you to programmatically manage &lt;a href=&quot;/dev/crawl&quot;&gt;Crawlbot&lt;/a&gt; crawls and retrieve output. Crawlbot API responses are in JSON format."/><meta property="og:image" content="https://diffbot.github.io/img/diagram.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://diffbot.github.io/img/diagram.svg"/><link rel="shortcut icon" href="/img/diffbot-head.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://diffbot.github.io/blog/atom.xml" title="Docs Suite Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://diffbot.github.io/blog/feed.xml" title="Docs Suite Blog RSS Feed"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/diffbot_white.svg" alt="Docs Suite"/><h2 class="headerTitleWithLogo">Docs Suite</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/en/intro" target="_self">Prose</a></li><li class="siteNavGroupActive"><a href="/docs/en/api-intro" target="_self">API</a></li><li class=""><a href="/docs/en/error-intro" target="_self">Debugging</a></li><li class=""><a href="/help" target="_self">Help</a></li><li class=""><a href="/blog/" target="_self">Blog</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Multi-URL APIs</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Automatic and Custom APIs<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/en/api-intro">Introduction</a></li><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Article API</h4><ul><li class="navListItem"><a class="navItem" href="/docs/en/api-article">Article Extraction API</a></li><li class="navListItem"><a class="navItem" href="/docs/en/api-article-html">Article API: HTML Field Specification</a></li><li class="navListItem"><a class="navItem" href="/docs/en/api-semantria">Semantria-Powered Text Analysis Features</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Analyze API</h4><ul><li class="navListItem"><a class="navItem" href="/docs/en/api-analyze">Analyze API</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Discussion API</h4><ul><li class="navListItem"><a class="navItem" href="/docs/en/api-discussion">Discussion Extraction API</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Media APIs</h4><ul><li class="navListItem"><a class="navItem" href="/docs/en/api-image">Image Extraction API</a></li><li class="navListItem"><a class="navItem" href="/docs/en/api-video">Video Extraction API</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Product API</h4><ul><li class="navListItem"><a class="navItem" href="/docs/en/api-product">Product Extraction API</a></li><li class="navListItem"><a class="navItem" href="/docs/en/api-product-normalized-specs">Product API: Normalized Specs</a></li><li class="navListItem"><a class="navItem" href="/docs/en/api-product-categories">Product API: Category Taxonomy</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Account API</h4><ul><li class="navListItem"><a class="navItem" href="/docs/en/api-account">Account API</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Multi-URL APIs</h4><ul><li class="navListItem navListItemActive"><a class="navItem" href="/docs/en/api-crawlbot-api">Crawlbot API</a></li><li class="navListItem"><a class="navItem" href="/docs/en/api-bulk">Bulk API</a></li><li class="navListItem"><a class="navItem" href="/docs/en/api-search">Search API</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Custom API</h4><ul><li class="navListItem"><a class="navItem" href="/docs/en/api-custom">Custom APIs</a></li><li class="navListItem"><a class="navItem" href="/docs/en/api-selectors-filters">Custom API Selectors and Filters</a></li><li class="navListItem"><a class="navItem" href="/docs/en/api-managing-rules-programmatically">Managing Custom Rules Programmatically</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Knowledge Graph<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/en/api-kg-intro">Introduction</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/diffbot/docs/edit/master/docs/api-crawlbot-api.md" target="_blank" rel="noreferrer noopener">Edit</a><h1 id="__docusaurus" class="postHeaderTitle">Crawlbot API</h1></header><article><div><span><p>The Crawlbot API allows you to programmatically manage <a href="/dev/crawl">Crawlbot</a> crawls and retrieve output. Crawlbot API responses are in JSON format.</p>
<h2><a class="anchor" aria-hidden="true" id="creating-or-updating-a-crawl"></a><a href="#creating-or-updating-a-crawl" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Creating or Updating a Crawl</h2>
<p><strong>Note that the limit of active crawls on a single token is 1000. More information <a href="/docs/en/error-too-many-collections">here</a>.</strong></p>
<p>To create a crawl, make a POST request to <code>https://api.diffbot.com/v3/crawl</code>.</p>
<p>Provide the following data:</p>
<table>
<thead>
<tr><th style="text-align:left">Argument</th><th style="text-align:left">Description</th></tr>
</thead>
<tbody>
<tr><td style="text-align:left"><code>token</code></td><td style="text-align:left">Developer <a href="https://www.diffbot.com/pricing">token</a>.</td></tr>
<tr><td style="text-align:left"><code>name</code></td><td style="text-align:left">Job name. This should be a unique identifier and can be used to modify your crawl or retrieve its output.</td></tr>
<tr><td style="text-align:left"><code>seeds</code></td><td style="text-align:left">Seed URL(s). Must be <a href="https://en.wikipedia.org/wiki/Percent-encoding">URL encoded</a>. Separate multiple URLs with whitespace to spider multiple sites within the same crawl. If the seed contains a non-www subdomain (&quot;<a href="https://blog.diffbot.com">https://blog.diffbot.com</a>&quot; or &quot;<a href="https://docs.diffbot.com">https://docs.diffbot.com</a>&quot;) Crawlbot will restrict spidering to the specified <strong>subdomain</strong>.</td></tr>
<tr><td style="text-align:left"><code>apiUrl</code></td><td style="text-align:left">Full Diffbot API URL through which to process pages. E.g., <code>&amp;apiUrl=https://api.diffbot.com/v3/article</code> to process matching links via the <a href="https://www.diffbot.com/products/automatic/article">Article API</a>. The Diffbot API URL can include querystring parameters to tailor the output. For example, <code>&amp;apiUrl=https://api.diffbot.com/v3/product?fields=querystring,meta</code> will process matching links using the <a href="https://www.diffbot.com/products/automatic/product">Product API</a>, and also return the <code>querystring</code> and <code>meta</code> fields.<br><br>To automatically identify and process content using our <a href="https://www.diffbot.com/products/automatic/analyze">Analyze API</a> (Smart Processing), pass <code>apiUrl=https://api.diffbot.com/v3/analyze?mode=auto</code> to return all page-types. See full Analyze API documentation under the <a href="/dev/docs">Automatic APIs documentation</a>.<br><br>Be sure to <a href="https://en.wikipedia.org/wiki/Percent-encoding">URL encode</a> your Diffbot API actions.</td></tr>
</tbody>
</table>
<p>You can refine your crawl using the following optional controls. <a href="/docs/en/explain-cvp">Read more on crawling versus processing</a>.</p>
<table>
<thead>
<tr><th style="text-align:left">Argument</th><th style="text-align:left">Description</th></tr>
</thead>
<tbody>
<tr><td style="text-align:left"><code>urlCrawlPattern</code></td><td style="text-align:left">Specify ||-separated <strong>strings</strong> to limit pages crawled to those whose URLs contain <em>any</em> of the content strings. You can use the exclamation point to specify a negative string, e.g. <code>!product</code> to exclude URLs containing the string &quot;product,&quot; and the <code>^</code> and <code>$</code> characters to limit matches to the beginning or end of the URL.<br><br>The use of a <code>urlCrawlPattern</code> will allow Crawlbot to spider outside of the seed domain; it will follow all matching URLs regardless of domain.</td></tr>
<tr><td style="text-align:left"><code>urlCrawlRegEx</code></td><td style="text-align:left">Specify a regular expression to limit pages <strong>crawled</strong> to those URLs that contain a match to your expression. This will override any <code>urlCrawlPattern</code> value.</td></tr>
<tr><td style="text-align:left"><code>urlProcessPattern</code></td><td style="text-align:left">Specify ||-separated <strong>strings</strong> to limit pages processed to those whose URLs contain <em>any</em> of the content strings. You can use the exclamation point to specify a negative string, e.g. <code>!/category</code> to exclude URLs containing the string &quot;/category,&quot; and the <code>^</code> and <code>$</code> characters to limit matches to the beginning or end of the URL.</td></tr>
<tr><td style="text-align:left"><code>urlProcessRegEx</code></td><td style="text-align:left">Specify a regular expression to limit pages <strong>processed</strong> to those URLs that contain a match to your expression. This will override any <code>urlProcessPattern</code> value.</td></tr>
<tr><td style="text-align:left"><code>pageProcessPattern</code></td><td style="text-align:left">Specify ||-separated strings to limit pages <strong>processed</strong> to those whose HTML contains <em>any</em> of the content strings.</td></tr>
</tbody>
</table>
<p>Additional (optional) Parameters:</p>
<table>
<thead>
<tr><th style="text-align:left">Argument</th><th style="text-align:left">Description</th></tr>
</thead>
<tbody>
<tr><td style="text-align:left"><code>customHeaders</code></td><td style="text-align:left">Set multiple custom headers to be used while crawling and processing pages sent to Diffbot APIs. Each header should be sent in its own <code>customHeaders</code> argument, with a colon delimiting the header name and value, and should be URL-encoded. For example, <code>&amp;customHeaders=Accept-Language%3Aen-us</code>. <a href="/docs/en/guides-custom-headers">See more information on using this functionality</a>.</td></tr>
<tr><td style="text-align:left"><code>useCanonical</code></td><td style="text-align:left">Pass <code>useCanonical=0</code> to disable deduplication of pages based on a canonical link definition. <a href="/docs/en/explain-page-deduplication">See more</a>.</td></tr>
<tr><td style="text-align:left"><code>obeyRobots</code></td><td style="text-align:left">Pass <code>obeyRobots=0</code> to ignore a site's robots.txt instructions. <a href="/docs/en/explain-robots-txt">See more</a>.</td></tr>
<tr><td style="text-align:left"><code>restrictDomain</code></td><td style="text-align:left">Pass <code>restrictDomain=0</code> to allow limited crawling across subdomains/domains. <a href="/docs/en/guides-restrict-domain">See more</a>.</td></tr>
<tr><td style="text-align:left"><code>useProxies</code></td><td style="text-align:left">Set value to <code>1</code> to force the use of proxy IPs for the crawl. This will utilize proxy servers for both crawling and processing of pages.</td></tr>
<tr><td style="text-align:left"><code>maxHops</code></td><td style="text-align:left">Specify the depth of your crawl. A <code>maxHops=0</code> will limit <strong>processing</strong> to the seed URL(s) only -- no other links will be processed; <code>maxHops=1</code> will process all (otherwise matching) pages whose links appear on seed URL(s); <code>maxHops=2</code> will process pages whose links appear on those pages; and so on.<br><br>By default (<code>maxHops=-1</code>) Crawlbot will crawl and process links at any depth.</td></tr>
<tr><td style="text-align:left"><code>maxToCrawl</code></td><td style="text-align:left">Specify max pages to spider. Default: 100,000.</td></tr>
<tr><td style="text-align:left"><code>maxToProcess</code></td><td style="text-align:left">Specify max pages to process through Diffbot APIs. Default: 100,000.</td></tr>
<tr><td style="text-align:left"><code>maxToCrawlPerSubdomain</code></td><td style="text-align:left">Specify max pages to spider per subdomain. Default: no limit (-1)</td></tr>
<tr><td style="text-align:left"><code>maxToProcessPerSubdomain</code></td><td style="text-align:left">Specify max pages to process per subdomain. Default: no limit (-1)</td></tr>
<tr><td style="text-align:left"><code>notifyEmail</code></td><td style="text-align:left">Send a message to this email address when the crawl hits the <code>maxToCrawl</code> or <code>maxToProcess</code> limit, or when the crawl completes.</td></tr>
<tr><td style="text-align:left"><code>notifyWebhook</code></td><td style="text-align:left">Pass a URL to be notified when the crawl hits the <code>maxToCrawl</code> or <code>maxToProcess</code> limit, or when the crawl completes. You will receive a POST with <code>X-Crawl-Name</code> and <code>X-Crawl-Status</code> in the headers, and the job's <a href="#json-metadata">JSON metadata</a> in the POST body. Note that in webhook POSTs the parent <code>jobs</code> will not be sent—only the individual job object will be returned.<br><br>We've integrated with Zapier to make webhooks even more powerful; <a href="/docs/en/guides-zapier">read more</a> on what you can do with Zapier and Diffbot.</td></tr>
<tr><td style="text-align:left"><code>crawlDelay</code></td><td style="text-align:left">Wait this many seconds between each URL crawled from a single IP address. Specify the number of seconds as an integer or floating-point number (e.g., <code>crawlDelay=0.25</code>).</td></tr>
<tr><td style="text-align:left"><code>repeat</code></td><td style="text-align:left">Specify the number of days as a floating-point (e.g. <code>repeat=7.0</code>) to repeat this crawl. By default crawls will not be repeated.</td></tr>
<tr><td style="text-align:left"><code>seedRecrawlFrequency</code></td><td style="text-align:left">Useful for specifying a frequency, in number of days, to recrawl seed urls, which is independent of the overall recrawl frequency given by <code>repeat</code>. Defaults to <code>seedRecrawlFrequency=-1</code> to use the default frequency.</td></tr>
<tr><td style="text-align:left"><code>onlyProcessIfNew</code></td><td style="text-align:left">By default repeat crawls will only process new (previously unprocessed) pages. Set to 0 (<code>onlyProcessIfNew=0</code>) to process all content on repeat crawls.</td></tr>
<tr><td style="text-align:left"><code>maxRounds</code></td><td style="text-align:left">Specify the maximum number of crawl repeats. By default (<code>maxRounds=0</code>) repeating crawls will continue indefinitely.</td></tr>
</tbody>
</table>
<!--
<h4><a name="filterExpressions"></a>URL Filter Expressions</h4>
<p>Crawlbot 2.0 features a powerful URL filtering engine allowing you to process URLs via myriad Diffbot APIs. You may pass multiple filters in each crawl. Each filter consists of an `expression` (the content to match) and an `action` (the processing or crawling action to take).</p>
<p>Filters are processed in the order in which they are sent in the querystring. URLs can only match a single filter.</p>
<table class="controls table table-bordered" border="0" cellpadding="5">
<tbody>
<tr><td colspan="2">**Expression options**</td></tr>
<tr><td>`expression=*`</td><td>Matches all (remaining) pages. If this is the first filter expression it will match all pages.</td></tr>
<tr><td>`expression=*string*`</td><td>Matches all (remaining) URLs containing the text string.</td></tr>
<tr><td>`expression=^*string*`</td><td>Matches all (remaining) URLs starting with the text string.</td></tr>
<tr><td>`expression=$*string*`</td><td>Matches all (remaining) URLs ending with the text string.</td></tr>
<tr><td>
<div>`expression=!*string*`,<br />
`expression=!^*string*`,<br />
`expression=!$*string*`</td><td>Matches all (remaining) URLs *not* containing, starting with, or ending with the text string.</td></tr>
<tr><td colspan="2">Multiple expressions can be combined in the same filter using `&&`. This will require all expressions to match. Ampersands should be url-encoded, e.g. `&expression=products%26%26^https%26%26!$.html`.</td></tr>
<tr><td colspan="2">**Filter actions**</td></tr>
<tr><td>`action=doNotCrawl`</td><td>Do not crawl/visit the matching pages.</td></tr>
<tr><td>`action=doNotProcess`</td><td>Do not process the matching pages. Will still crawl the matching pages for links.</td></tr>
<tr><td>`action=*Diffbot API*`</td><td>Process the matching pages via the specified Diffbot API.
</td></tr>
</tbody>
</table>
-->
<h3><a class="anchor" aria-hidden="true" id="response"></a><a href="#response" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Response</h3>
<p>Upon adding a new crawl, you will receive a success message in the JSON response, in addition to full crawl details:</p>
<pre><code class="hljs css language-json">"response": "Successfully added urls for spidering."
</code></pre>
<p>Please note that if you get the &quot;Too Many Collections&quot; error, you hit our 1000-active-crawls limit. More information <a href="/docs/en/error-too-many-collections">here</a>.</p>
<h2><a class="anchor" aria-hidden="true" id="pausing-restarting-or-deleting-crawls"></a><a href="#pausing-restarting-or-deleting-crawls" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Pausing, Restarting or Deleting Crawls</h2>
<p>You can manage your crawls by making POST requests to the same endpoint, <code>https://api.diffbot.com/v3/crawl</code>.</p>
<p>Provide the following data:</p>
<table>
<thead>
<tr><th style="text-align:left">Argument</th><th style="text-align:left">Description</th></tr>
</thead>
<tbody>
<tr><td style="text-align:left"><code>token</code></td><td style="text-align:left">Developer <a href="https://diffbot.com/pricing">token</a>.</td></tr>
<tr><td style="text-align:left"><code>name</code></td><td style="text-align:left">Job name as defined when the crawl was created. </td></tr><td colspan="2"><strong>Job-control arguments</strong></td></tr>
<tr><td style="text-align:left"><code>roundStart</code></td><td style="text-align:left">Pass <code>roundStart=1</code> to force the start of a new crawl &quot;round&quot; (manually repeat the crawl). If <code>onlyProcessIfNew</code> is set to 1 (default), only newly-created pages will be processed.</td></tr>
<tr><td style="text-align:left"><code>pause</code></td><td style="text-align:left">Pass <code>pause=1</code> to pause a crawl. Pass <code>pause=0</code> to resume a paused crawl.</td></tr>
<tr><td style="text-align:left"><code>restart</code></td><td style="text-align:left">Restart removes all crawled data while maintaining crawl settings. Pass <code>restart=1</code> to restart a crawl.</td></tr>
<tr><td style="text-align:left"><code>delete</code></td><td style="text-align:left">Pass <code>delete=1</code> to delete a crawl, and all associated data, completely.</td></tr>
</tbody>
</table>
<h2><a class="anchor" aria-hidden="true" id="retrieving-crawlbot-api-data"></a><a href="#retrieving-crawlbot-api-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Retrieving Crawlbot API Data</h2>
<p>To download results please make a GET request to <code>https://api.diffbot.com/v3/crawl/data</code>. Provide the following arguments based on the data you need. By default the complete extracted JSON data will be downloaded.</p>
<table>
<thead>
<tr><th style="text-align:left">Argument</th><th style="text-align:left">Description</th></tr>
</thead>
<tbody>
<tr><td style="text-align:left"><code>token</code></td><td style="text-align:left">Developer <a href="https://diffbot.com/pricing">token</a>.</td></tr>
<tr><td style="text-align:left"><code>name</code></td><td style="text-align:left">Name of the crawl whose data you wish to download.</td></tr>
<tr><td style="text-align:left"><code>format</code></td><td style="text-align:left">Request <code>format=csv</code> to download the extracted data in CSV format (default: <code>json</code>). Note that CSV files will only contain top-level fields. </td></tr><td colspan="2"><strong>For diagnostic data:</strong></td></td></tr>
<tr><td style="text-align:left"><code>type</code></td><td style="text-align:left">Request <code>type=urls</code> to retrieve the crawl <a href="/docs/en/explain-crawl-url-report">URL Report</a> (CSV).</td></tr>
<tr><td style="text-align:left"><code>num</code></td><td style="text-align:left">Pass an integer value (e.g. <code>num=100</code>) to request a subset of URLs, most recently crawled first.</td></tr>
</tbody>
</table>
<h2><a class="anchor" aria-hidden="true" id="using-the-search-api-to-retrieve-crawl-data"></a><a href="#using-the-search-api-to-retrieve-crawl-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Using the Search API to Retrieve Crawl Data</h2>
<p>You can also use Diffbot's <a href="/docs/en/api-search">Search API</a> to fine-tune the data retrieved from your Crawlbot or Bulk API jobs.</p>
<p><a href="/docs/en/api-search">Search API documentation</a></p>
<h2><a class="anchor" aria-hidden="true" id="viewing-crawl-details"></a><a href="#viewing-crawl-details" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Viewing Crawl Details</h2>
<p>Your crawls (along with any Bulk API jobs) will be returned in the <code>jobs</code> object in a request made to <code>https://api.diffbot.com/v3/crawl</code>.</p>
<p>To retrieve a single crawl's details, provide the crawl's <code>name</code> in your request:</p>
<table>
<thead>
<tr><th style="text-align:left">Argument</th><th style="text-align:left">Description</th></tr>
</thead>
<tbody>
<tr><td style="text-align:left"><code>token</code></td><td style="text-align:left">Developer <a href="https://diffbot.com/pricing">token</a>.</td></tr>
<tr><td style="text-align:left"><code>name</code></td><td style="text-align:left">Name of crawl to retrieve.</td></tr>
</tbody>
</table>
<p>To view all crawls (and bulk jobs), simply omit the <code>name</code> parameter: <code>https://api.diffbot.com/v3/crawl?token={{token}}</code></p>
<p><a name="json-metadata"></a></p>
<h3><a class="anchor" aria-hidden="true" id="response-1"></a><a href="#response-1" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Response</h3>
<p>This will return a JSON response of your token's crawls (and Bulk API) jobs in the <code>jobs</code> object. If you have specified a single job name, only one job's details will be returned.</p>
<p>Sample response from a single crawl:</p>
<pre><code class="hljs css language-json">{
  <span class="hljs-attr">"jobs"</span>: [
    {
      <span class="hljs-attr">"name"</span>: <span class="hljs-string">"crawlJob"</span>,
      <span class="hljs-attr">"type"</span>: <span class="hljs-string">"crawl"</span>,
      <span class="hljs-attr">"jobCreationTimeUTC"</span>: <span class="hljs-number">1427410692</span>,
      <span class="hljs-attr">"jobCompletionTimeUTC"</span>: <span class="hljs-number">1427410798</span>,
      <span class="hljs-attr">"jobStatus"</span>: {
        <span class="hljs-attr">"status"</span>: <span class="hljs-number">9</span>,
        <span class="hljs-attr">"message"</span>: <span class="hljs-string">"Job has completed and no repeat is scheduled."</span>
      },
      <span class="hljs-attr">"sentJobDoneNotification"</span>: <span class="hljs-number">1</span>,
      <span class="hljs-attr">"objectsFound"</span>: <span class="hljs-number">177</span>,
      <span class="hljs-attr">"urlsHarvested"</span>: <span class="hljs-number">2152</span>,
      <span class="hljs-attr">"pageCrawlAttempts"</span>: <span class="hljs-number">367</span>,
      <span class="hljs-attr">"pageCrawlSuccesses"</span>: <span class="hljs-number">365</span>,
      <span class="hljs-attr">"pageCrawlSuccessesThisRound"</span>: <span class="hljs-number">365</span>,
      <span class="hljs-attr">"pageProcessAttempts"</span>: <span class="hljs-number">210</span>,
      <span class="hljs-attr">"pageProcessSuccesses"</span>: <span class="hljs-number">210</span>,
      <span class="hljs-attr">"pageProcessSuccessesThisRound"</span>: <span class="hljs-number">210</span>,
      <span class="hljs-attr">"maxRounds"</span>: <span class="hljs-number">0</span>,
      <span class="hljs-attr">"repeat"</span>: <span class="hljs-number">0.0</span>,
      <span class="hljs-attr">"crawlDelay"</span>: <span class="hljs-number">0.25</span>,
      <span class="hljs-attr">"obeyRobots"</span>: <span class="hljs-number">1</span>,
      <span class="hljs-attr">"maxToCrawl"</span>: <span class="hljs-number">100000</span>,
      <span class="hljs-attr">"maxToProcess"</span>: <span class="hljs-number">100000</span>,
      <span class="hljs-attr">"onlyProcessIfNew"</span>: <span class="hljs-number">1</span>,
      <span class="hljs-attr">"seeds"</span>: <span class="hljs-string">"http://docs.diffbot.com"</span>,
      <span class="hljs-attr">"roundsCompleted"</span>: <span class="hljs-number">0</span>,
      <span class="hljs-attr">"roundStartTime"</span>: <span class="hljs-number">0</span>,
      <span class="hljs-attr">"currentTime"</span>: <span class="hljs-number">1443822683</span>,
      <span class="hljs-attr">"currentTimeUTC"</span>: <span class="hljs-number">1443822683</span>,
      <span class="hljs-attr">"apiUrl"</span>: <span class="hljs-string">"https://api.diffbot.com/v3/analyze"</span>,
      <span class="hljs-attr">"urlCrawlPattern"</span>: <span class="hljs-string">""</span>,
      <span class="hljs-attr">"urlProcessPattern"</span>: <span class="hljs-string">""</span>,
      <span class="hljs-attr">"pageProcessPattern"</span>: <span class="hljs-string">""</span>,
      <span class="hljs-attr">"urlCrawlRegEx"</span>: <span class="hljs-string">""</span>,
      <span class="hljs-attr">"urlProcessRegEx"</span>: <span class="hljs-string">""</span>,
      <span class="hljs-attr">"maxHops"</span>: <span class="hljs-number">-1</span>,
      <span class="hljs-attr">"downloadJson"</span>: <span class="hljs-string">"http://api.diffbot.com/v3/crawl/download/sampletoken-crawlJob_data.json"</span>,
      <span class="hljs-attr">"downloadUrls"</span>: <span class="hljs-string">"http://api.diffbot.com/v3/crawl/download/sampletoken-crawlJob_urls.csv"</span>,
      <span class="hljs-attr">"notifyEmail"</span>: <span class="hljs-string">"support@diffbot.com"</span>,
      <span class="hljs-attr">"notifyWebhook"</span>: <span class="hljs-string">"http://www.diffbot.com"</span>
    }
  ]
}
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="status-codes"></a><a href="#status-codes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Status Codes</h2>
<p>The <code>jobStatus</code> object will return the following status codes and associated messages:</p>
<table>
<thead>
<tr><th style="text-align:left">Status</th><th style="text-align:left">Message</th></tr>
</thead>
<tbody>
<tr><td style="text-align:left">0</td><td style="text-align:left">Job is initializing</td></tr>
<tr><td style="text-align:left">1</td><td style="text-align:left">Job has reached maxRounds limit</td></tr>
<tr><td style="text-align:left">2</td><td style="text-align:left">Job has reached maxToCrawl limit</td></tr>
<tr><td style="text-align:left">3</td><td style="text-align:left">Job has reached maxToProcess limit</td></tr>
<tr><td style="text-align:left">4</td><td style="text-align:left">Next round to start in _____ seconds</td></tr>
<tr><td style="text-align:left">5</td><td style="text-align:left">No URLs were added to the crawl</td></tr>
<tr><td style="text-align:left">6</td><td style="text-align:left">Job paused</td></tr>
<tr><td style="text-align:left">7</td><td style="text-align:left">Job in progress</td></tr>
<tr><td style="text-align:left">8</td><td style="text-align:left">All crawling temporarily paused by root administrator for maintenance</td></tr>
<tr><td style="text-align:left">9</td><td style="text-align:left">Job has completed and no repeat is scheduled</td></tr>
<tr><td style="text-align:left">10</td><td style="text-align:left">Failed to crawl any seed<br><em>Indicates a problem retrieving links from the seed URL(s)</em></td></tr>
</tbody>
</table>
</span></div></article></div><div class="docLastUpdate"><em>Last updated by Bruno Skvorc</em></div><div class="docs-prevnext"><a class="docs-prev button" href="/docs/en/api-account"><span class="arrow-prev">← </span><span>Account API</span></a><a class="docs-next button" href="/docs/en/api-bulk"><span>Bulk API</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#creating-or-updating-a-crawl">Creating or Updating a Crawl</a><ul class="toc-headings"><li><a href="#response">Response</a></li></ul></li><li><a href="#pausing-restarting-or-deleting-crawls">Pausing, Restarting or Deleting Crawls</a></li><li><a href="#retrieving-crawlbot-api-data">Retrieving Crawlbot API Data</a></li><li><a href="#using-the-search-api-to-retrieve-crawl-data">Using the Search API to Retrieve Crawl Data</a></li><li><a href="#viewing-crawl-details">Viewing Crawl Details</a><ul class="toc-headings"><li><a href="#response-1">Response</a></li></ul></li><li><a href="#status-codes">Status Codes</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/diffbot_white.svg" alt="Docs Suite" width="66" height="58"/></a><div><h5>Docs</h5><a href="/docs/en/intro">Tutorials</a><a href="/docs/en/guides-intro">How-to Guides</a><a href="/docs/en/explain-intro">Explainers</a><a href="/docs/en/api-intro">API Reference</a></div><div><h5>Community</h5><a href="https://stackoverflow.com/questions/tagged/diffbot" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://twitter.com/diffbot" target="_blank" rel="noreferrer noopener">Twitter</a></div><div><h5>More</h5><a href="/blog">Blog</a><a href="https://github.com/diffbot">GitHub</a></div></section><a href="https://diffbot.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/diffbot_white.svg" alt="Diffbot.com" width="170" height="45"/></a><section class="copyright">Copyright © 2020 Diffbot.com</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '2c24e5e78d724e77c46ef1b720700177',
                indexName: 'diffbot',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>
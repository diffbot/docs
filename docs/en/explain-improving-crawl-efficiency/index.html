<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Improving Crawl Efficiency · Docs Suite</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Crawlbot jobs must first crawl pages for links and then process pages by submitting them to a Diffbot Extraction API. (See [The Difference Between Crawling and Processing](explain-crawling-versus-processing) for more on this.) Each crawled page requires that Crawlbot make at least one request to the target website and check the response for links, but if the page is not processed this won&#x27;t add any data to the job&#x27;s results. If a Crawlbot job is crawling many more pages than it is processing, the job will run slowly."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Improving Crawl Efficiency · Docs Suite"/><meta property="og:type" content="website"/><meta property="og:url" content="https://diffbot.github.io/"/><meta property="og:description" content="Crawlbot jobs must first crawl pages for links and then process pages by submitting them to a Diffbot Extraction API. (See [The Difference Between Crawling and Processing](explain-crawling-versus-processing) for more on this.) Each crawled page requires that Crawlbot make at least one request to the target website and check the response for links, but if the page is not processed this won&#x27;t add any data to the job&#x27;s results. If a Crawlbot job is crawling many more pages than it is processing, the job will run slowly."/><meta property="og:image" content="https://diffbot.github.io/img/diagram.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://diffbot.github.io/img/diagram.svg"/><link rel="shortcut icon" href="/img/diffbot-head.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/app.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/diffbot_white.svg" alt="Docs Suite"/><h2 class="headerTitleWithLogo">Docs Suite</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/en/error-intro" target="_self">Debugging</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Basics</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Crawlbot<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Basics</h4><ul><li class="navListItem"><a class="navItem" href="/docs/en/cb-intro-cb">Introduction</a></li><li class="navListItem"><a class="navItem" href="/docs/en/cb-basics-cb">Basic Usage</a></li><li class="navListItem"><a class="navItem" href="/docs/en/tutorials-crawl-video">Crawlbot Video Tutorials</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/docs/en/explain-improving-crawl-efficiency">Improving Crawl Efficiency</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Recipes</h4><ul><li class="navListItem"><a class="navItem" href="/docs/en/cb-usage-cb">Index</a></li><li class="navListItem"><a class="navItem" href="/docs/en/guides-authenticated-crawling">Authenticated Crawling</a></li><li class="navListItem"><a class="navItem" href="/docs/en/guides-check-results-specific-page-type">Checking number of results per result type</a></li><li class="navListItem"><a class="navItem" href="/docs/en/guides-crawling-ajax-generated-links">Crawling JavaScript-generated links</a></li><li class="navListItem"><a class="navItem" href="/docs/en/guides-custom-headers-crawl">How do I set custom headers while crawling?</a></li><li class="navListItem"><a class="navItem" href="/docs/en/guides-crawlbot-custom-proxies">Crawling with Custom Proxies</a></li><li class="navListItem"><a class="navItem" href="/docs/en/guides-job-limits">Controlling the number of Active Crawl jobs</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">API</h4><ul><li class="navListItem"><a class="navItem" href="/docs/en/api-crawlbot-api">Crawlbot API</a></li></ul></div></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/diffbot/docs/edit/master/docs/explain-improving-crawl-efficiency.md" target="_blank" rel="noreferrer noopener">Edit</a><h1 id="__docusaurus" class="postHeaderTitle">Improving Crawl Efficiency</h1></header><article><div><span><p>Crawlbot jobs must first crawl pages for links and then process pages by submitting them to a Diffbot Extraction API. (See <a href="explain-crawling-versus-processing">The Difference Between Crawling and Processing</a> for more on this.) Each crawled page requires that Crawlbot make at least one request to the target website and check the response for links, but if the page is not processed this won't add any data to the job's results. If a Crawlbot job is crawling many more pages than it is processing, the job will run slowly.</p>
<p>Because of this, when using <a href="guides-patterns">patterns and regexes</a> to narrow the pages crawled or processed by a Crawlbot job it's best to do as much of the narrowing as possible in the <em>crawling</em> stage rather than relying on it only in the <em>processing</em> stage.</p>
<p>For example, suppose there is a site you'd like to crawl for articles and you are not interested in its other content. You notice the articles have URLs like <code>https://example.com/2020/01/improving-inefficient-crawls/</code> so you consider running a crawl with a configuration like the following:</p>
<ul>
<li>Seed URL: <code>https://example.com</code></li>
<li>Crawl Patterns: <em>none</em></li>
<li>Crawl Regex: <em>none</em></li>
<li>Processing Patterns: <em>none</em></li>
<li>Processing Regex: <code>https:\/\/example\.com\/\d+\/\d+\/[\w-]+\/</code></li>
</ul>
<p>This would result in processing all the articles and no other pages. However, it would also mean that Crawlbot would crawl the entire site even though it only processes the articles. That's a lot of pages downloaded and crawled just to be thrown away. It's likely that this crawl would end up being very slow.</p>
<p>A better approach is to more strongly constrain the crawling to avoid crawling many pages that will not be processed. Suppose the site's article archive pages have URLs like <code>https://example.com/articles/</code>, <code>https://example.com/articles/page/2/</code>, <code>https://example.com/articles/page/3/</code> and so on. You could then crawl these archive pages and process the articles linked from them and skip crawling the rest of the site, like so:</p>
<ul>
<li>Seed URL: <code>https://example.com/articles/</code></li>
<li>Crawl Patterns: <code>https://example.com/articles/page/</code></li>
<li>Crawl Regex: <em>none</em></li>
<li>Processing Patterns: <em>none</em></li>
<li>Processing Regex: <code>https:\/\/example\.com\/\d+\/\d+\/[\w-]+\/</code></li>
</ul>
<p>This way you'd only crawl the article archive pages and process the article pages. There'd be no extra time waiting while the rest of the site is crawled without adding any useful data to your results. This crawl would gather the same results in a much shorter time.</p>
</span></div></article></div><div class="docLastUpdate"><em>Last updated by Dan Urman</em></div><div class="docs-prevnext"><a class="docs-prev button" href="/docs/en/tutorials-crawl-video"><span class="arrow-prev">← </span><span>Crawlbot Video Tutorials</span></a><a class="docs-next button" href="/docs/en/cb-usage-cb"><span>Index</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/diffbot_white.svg" alt="Docs Suite" width="66" height="58"/></a><div><h5>Docs</h5><a href="/docs/en/api-basics-index">Extraction</a><a href="/docs/en/cb-basics-index">Crawling</a><a href="/docs/en/kg-index">Knowledge Graph</a><a href="/docs/en/explain-gdpr">Diffbot and GDPR</a></div><div><h5>Community</h5><a href="https://stackoverflow.com/questions/tagged/diffbot" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://twitter.com/diffbot" target="_blank" rel="noreferrer noopener">Twitter</a></div><div><h5>More</h5><a href="/blog">Blog</a><a href="/help">Help</a><a href="https://github.com/diffbot">GitHub</a></div></section><a href="https://diffbot.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/diffbot_white.svg" alt="Diffbot.com" width="170" height="45"/></a><section class="copyright">Copyright © 2023 Diffbot.com</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '2c24e5e78d724e77c46ef1b720700177',
                indexName: 'diffbot',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>